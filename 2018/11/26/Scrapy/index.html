<!DOCTYPE html><html lang="zh-CN"><head><meta charset="UTF-8"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=2"><meta name="theme-color" content="#222"><meta name="generator" content="Hexo 3.9.0"><link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png"><link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png"><link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png"><link rel="mask-icon" href="/images/logo.svg" color="#222"><link rel="alternate" href="/atom.xml" title="中·庸" type="application/atom+xml"><link rel="stylesheet" href="/css/main.css"><link rel="stylesheet" href="//cdn.jsdelivr.net/npm/font-awesome@4/css/font-awesome.min.css"><script id="hexo-configurations">var NexT=window.NexT||{},CONFIG={hostname:new URL("yuwengeng.coding.me/hexo-blog").hostname,root:"/",scheme:"Muse",version:"7.5.0",exturl:!1,sidebar:{position:"right","Muse | Mist":320,display:"post",offset:12,onmobile:!0},copycode:{enable:!0,show_result:!0,style:null},back2top:{enable:!0,sidebar:!1,scrollpercent:!1},bookmark:{enable:!1,color:"#222",save:"auto"},fancybox:!1,mediumzoom:!1,lazyload:!1,pangu:!1,algolia:{appID:"",apiKey:"",indexName:"",hits:{per_page:10},labels:{input_placeholder:"Search for Posts",hits_empty:"We didn't find any results for the search: ${query}",hits_stats:"${hits} results found in ${time} ms"}},localsearch:{enable:!1,trigger:"auto",top_n_per_article:1,unescape:!1,preload:!1},path:"",motion:{enable:!1,async:!1,transition:{post_block:"fadeIn",post_header:"slideDownIn",post_body:"slideDownIn",coll_header:"slideLeftIn",sidebar:"slideUpIn"}},sidebarPadding:40}</script><meta name="description" content="经典爬虫框架：1. url 管理器：Scheduler调度器     主要两个变量：已爬取url集合，未爬取集合；     去重：内存去重；           缓存数据库去重，布隆算法过滤  2. 下载器："><meta name="keywords" content="爬虫"><meta property="og:type" content="article"><meta property="og:title" content="Scrapy框架"><meta property="og:url" content="yuwengeng.coding.me/hexo-blog/2018/11/26/Scrapy/index.html"><meta property="og:site_name" content="中·庸"><meta property="og:description" content="经典爬虫框架：1. url 管理器：Scheduler调度器     主要两个变量：已爬取url集合，未爬取集合；     去重：内存去重；           缓存数据库去重，布隆算法过滤  2. 下载器："><meta property="og:locale" content="zh-CN"><meta property="og:updated_time" content="2019-11-09T15:05:13.807Z"><meta name="twitter:card" content="summary"><meta name="twitter:title" content="Scrapy框架"><meta name="twitter:description" content="经典爬虫框架：1. url 管理器：Scheduler调度器     主要两个变量：已爬取url集合，未爬取集合；     去重：内存去重；           缓存数据库去重，布隆算法过滤  2. 下载器："><link rel="canonical" href="yuwengeng.coding.me/hexo-blog/2018/11/26/Scrapy/"><script id="page-configurations">CONFIG.page={sidebar:"",isHome:!1,isPost:!0,isPage:!1,isArchive:!1}</script><title>Scrapy框架 | 中·庸</title><noscript><style>.sidebar-inner,.use-motion .brand,.use-motion .collection-header,.use-motion .comments,.use-motion .menu-item,.use-motion .pagination,.use-motion .post-block,.use-motion .post-body,.use-motion .post-header{opacity:initial}.use-motion .site-subtitle,.use-motion .site-title{opacity:initial;top:initial}.use-motion .logo-line-before i{left:initial}.use-motion .logo-line-after i{right:initial}</style></noscript></head><body itemscope itemtype="http://schema.org/WebPage"><div class="container"><div class="headband"></div><header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="header-inner"><div class="site-brand-container"><div class="site-meta"><div><a href="/" class="brand" rel="start"><span class="logo-line-before"><i></i></span> <span class="site-title">中·庸</span> <span class="logo-line-after"><i></i></span></a></div><p class="site-subtitle">斯人若彩虹，遇上方知有</p></div><div class="site-nav-toggle"><div class="toggle" aria-label="切换导航栏"><span class="toggle-line toggle-line-first"></span> <span class="toggle-line toggle-line-middle"></span> <span class="toggle-line toggle-line-last"></span></div></div></div><nav class="site-nav"><ul id="menu" class="menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-fw fa-home"></i>首页</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-fw fa-tags"></i>标签<span class="badge">10</span></a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-fw fa-th"></i>分类<span class="badge">10</span></a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-fw fa-archive"></i>归档<span class="badge">11</span></a></li><li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="fa fa-fw fa-user"></i>关于</a></li></ul></nav></div></header><div class="back-to-top"><i class="fa fa-arrow-up"></i> <span>0%</span></div><main class="main"><div class="main-inner"><div class="content-wrap"><div class="content"><div class="posts-expand"><article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN"><link itemprop="mainEntityOfPage" href="yuwengeng.coding.me/hexo-blog/2018/11/26/Scrapy/"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="/images/avatar.gif"><meta itemprop="name" content="zhiheng"><meta itemprop="description" content="programming and life"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="中·庸"></span><header class="post-header"><h1 class="post-title" itemprop="name headline">Scrapy框架</h1><div class="post-meta"><span class="post-meta-item"><span class="post-meta-item-icon"><i class="fa fa-calendar-o"></i> </span><span class="post-meta-item-text">发表于</span> <time title="创建时间：2018-11-26 17:08:58" itemprop="dateCreated datePublished" datetime="2018-11-26T17:08:58+08:00">2018-11-26</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="fa fa-calendar-check-o"></i> </span><span class="post-meta-item-text">更新于</span> <time title="修改时间：2019-11-09 23:05:13" itemprop="dateModified" datetime="2019-11-09T23:05:13+08:00">2019-11-09</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="fa fa-folder-o"></i> </span><span class="post-meta-item-text">分类于</span> <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/scrapy/" itemprop="url" rel="index"><span itemprop="name">scrapy</span> </a></span>， <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/scrapy/爬虫/" itemprop="url" rel="index"><span itemprop="name">爬虫</span> </a></span></span><span class="post-meta-item" title="阅读次数" id="busuanzi_container_page_pv" style="display:none"><span class="post-meta-item-icon"><i class="fa fa-eye"></i> </span><span class="post-meta-item-text">阅读次数：</span> <span id="busuanzi_value_page_pv"></span></span></div></header><div class="post-body" itemprop="articleBody"><h2 id="经典爬虫框架："><a href="#经典爬虫框架：" class="headerlink" title="经典爬虫框架："></a>经典爬虫框架：</h2><pre><code>1. url 管理器：Scheduler调度器
    主要两个变量：已爬取url集合，未爬取集合；
    去重：内存去重；
          缓存数据库去重，布隆算法过滤

2. 下载器：</code></pre><a id="more"></a><p>logging模块：保存持久化日志信息</p><h2 id="scrapy框架-任务分离固定明确"><a href="#scrapy框架-任务分离固定明确" class="headerlink" title="scrapy框架: 任务分离固定明确"></a>scrapy框架: 任务分离固定明确</h2><blockquote><p>框架中数据流：request，response，item<br>item会内部返回给pipline 在管道间传递 ,先在settings中开启pipline<br>Spider opened 开启</p></blockquote><p>scrapy shell url 进行快速调试<br>scrapy check 检查代码是否有错误<br>scrapy list列出所有可用的爬虫<br>scrapy fetch url 源代码下载下来并显示出来</p><h3 id="spider主程序："><a href="#spider主程序：" class="headerlink" title="spider主程序："></a>spider主程序：</h3><ul><li><p>被继承的基类scrapy.Spider中:<br>属性：</p><p>方法：</p><ol><li><p>start_requests() 这个方法必须返回一个可迭代对象</p></li><li><p>parse(response) 默认的回调函数<br>从生成器取尽第一部分的 request，然后再获取第二部分的 item，取到 item 了，就会放<br>到对应的 pipeline处理；<br>取尽之后，parse()⼯作结束，引擎再根据队列和 pipelines 中的内容去执⾏相<br>应的操作；</p><ol start="8"><li>程序在取得各个⻚⾯的 items 前，会先处理完之前所有的 request 队列⾥的请求<br>，然后再提取 items。</li><li>这⼀切的⼀切，Scrapy 引擎和调度器将负责到底。<br>yield 返回Request，dict None BaseItem</li></ol><ul><li>CrawlSpider类: 自动匹配响应的规律url，构造二次Request ，url自动修正[parse.urljoin()]； 定义rules匹配规则； follow=True提取的url响应中继续跟进匹配；<br>Rule(LinkExtractor(allow=re,restrict_css(),restrict_path()),callback=’parse’)<br>scrapy genspider -t crawl<br>使用场景：<br>url规律能被正则或xpath匹配<br>实现自动翻页<h3 id="settings："><a href="#settings：" class="headerlink" title="settings："></a>settings：</h3>LOG_LEVEL = “WARNING” debug info #设置scrapy日志等级<br>数据库初始化:<br>REDIS_URL = “redis://127.0.0.1:6379”</li></ul></li></ol></li></ul><h3 id="requests对象：scrapy-Request-类实例化"><a href="#requests对象：scrapy-Request-类实例化" class="headerlink" title="requests对象：scrapy.Request()类实例化"></a>requests对象：scrapy.Request()类实例化</h3><pre><code>- Request类常用参数：
    callback，
    dont_filter=True不过滤，默认对url去重
    meta:元数据字典 item{}，在不同解析函数中传递item数据  注意item层级多时 用deepcopy()防止同一引用污染。
    headers,
    cookies={} # cookies只能单独设置，不在headers

    priority=0，请求优先级

- scrapy post请求模拟登录:
    scrapy.FormRequest(url,formdata,callback) 

        # 自动从响应中找到form表单字段进行登录
        FormRequest.from_response(
            response,
            formdata,# 只需写user poassword 
            formid=None,
            formname=None,
        )</code></pre><h3 id="response对象："><a href="#response对象：" class="headerlink" title="response对象："></a>response对象：</h3><pre><code>    shell: 【response.加tab】
        res.body相当于res.content
        res.url 发起请求的url
        res.text
        res.meta{}
selector选中元素方法：xpath，css ，返回selector对象list

提取数据对象data属性：
extract()方法 序列化选中内容为Unicode 字符串 并返回字符串列表
extract_first():直接返回字符串</code></pre><h3 id="Item："><a href="#Item：" class="headerlink" title="Item："></a>Item：</h3><pre><code>初始化要爬取的Item类 实例化后为dict类型，以便为字段赋值</code></pre><h3 id="item-pipeline管道处理组件"><a href="#item-pipeline管道处理组件" class="headerlink" title="item pipeline管道处理组件:"></a>item pipeline管道处理组件:</h3><pre><code>必有process_item(self,item,spider)方法，必须返回item，以便继续处理

初始化数据库连接:
- open_spider(self,spider) # 相当于爬之前先开盖
- close_spider(self,spider)

- scrapy 保存信息的最简单的⽅法主要有四种，-o 输出指定格式的⽂件 【json csv xml jsonl】</code></pre><h3 id="中间件"><a href="#中间件" class="headerlink" title="中间件"></a>中间件</h3><ol><li><p>Downloader middleware： 用于修改request和response （ 代理池，UA库，）<br>process_request(request,spider)被调用</p><p>process_response(request, response, spider)</p><h2 id="process-exception-request-exception-spider"><a href="#process-exception-request-exception-spider" class="headerlink" title=" process_exception(request, exception, spider)"></a> process_exception(request, exception, spider)</h2><ul><li><p>重写RandomUserAgentMiddlware：<br>from fake_useragent import UserAgent</p><h1 id="引入开源库"><a href="#引入开源库" class="headerlink" title="引入开源库"></a>引入开源库</h1><p>class RandomUserAgentMiddlware(object):</p><p>def <strong>init</strong>(self, crawler):</p><pre><code>super(RandomUserAgentMiddlware, self).__init__()
self.ua = UserAgent()
#可读取在settings文件中的配置，来决定开源库ua执行的方法，默认是random，也可是ie、Firefox等等
self.ua_type = crawler.settings.get(&quot;RANDOM_UA_TYPE&quot;, &quot;random&quot;)</code></pre><p>@classmethod<br>def from_crawler(cls, crawler):</p><pre><code>return cls(crawler)</code></pre><p>#更换用户代理逻辑在此方法中<br>def process_request(self, request, spider):</p><pre><code>def get_ua():
    return getattr(self.ua, self.ua_type)

&lt;!-- print  get_ua()2 --&gt;
request.headers.setdefault(&apos;User-Agent&apos;, get_ua())</code></pre><p>添加代理：request.meta[‘proxy’] =</p></li></ul></li><li><p>Spider Middleware</p></li></ol><h3 id="异步加多线程"><a href="#异步加多线程" class="headerlink" title="异步加多线程"></a>异步加多线程</h3><h3 id="分布式爬虫-多台主机协同爬取"><a href="#分布式爬虫-多台主机协同爬取" class="headerlink" title="分布式爬虫-多台主机协同爬取"></a>分布式爬虫-多台主机协同爬取</h3><blockquote><p>爬取队列 Queue必须始终为一个，也就是共享爬取队列 ；这样才能保证 Scheduer 从队列里调度某个 Request 之后，其他Scheduler 不会重复调度此 Request ，就可以做到多个 Schduler 同步爬取 这就是分布式爬虫的基本雏形<br><strong>分布式架构</strong></p></blockquote><ol><li><p>维护爬取队列</p><p>Redis 支持的这几种数据结构存储各有优点：<br>列表有 lpush （） lpop （） rpush （） rpop （）方法，我们可以用它来实现先进先出式爬取队列，也可以实现先进后出栈式爬取队列<br>集合的元素是无序的且不重复的，这样我们可以非常方便地实现随机排序且不重复的爬取队列<br>有序集合带有分数表示，而 Scrapy的Request 也有优先级的控制，我们可以用它来实现带优先级调度的队列</p><p>我们需要根据具体爬虫的需求来灵活选择不同的队列</p></li><li><p>如何去重</p><blockquote><p>Scrapy 有自动去重，它的去重使用了 Python 中的集合，生成哈希指纹（忽略request headers）<br>scrapy单个Request队列放在内存中<br>分布式去重则把各个主机的request都存在一个redis数据库集合中，由此判断去重</p></blockquote></li><li><p>防止中断，断点续爬</p><p>保存队列在本地<br>scrapy crawl spider -s JOB_DIR=crawls/spider</p></li></ol><h3 id="RedisSpider"><a href="#RedisSpider" class="headerlink" title="RedisSpider()"></a>RedisSpider()</h3><p>部分修改<br>from scrapy_redis.spiders import RedisSpider<br>redis_key=”” #带爬取队列,从中读取start_url</p><p>自定义request:<br>def make_request_from_data(self, data): # RedisSpider内置方法,data来自redis<br>def start_requests(self):</p><h1 id="redis-cli"><a href="#redis-cli" class="headerlink" title="redis-cli:"></a>redis-cli:</h1><p>keys *<br>lpush key_name url</p></div><footer class="post-footer"><div class="post-tags"><a href="/tags/爬虫/" rel="tag"># 爬虫</a></div><div class="post-nav"><div class="post-nav-item"><a href="/2018/11/26/es-note/" rel="prev" title="python操作es"><i class="fa fa-chevron-left"></i> python操作es</a></div><div class="post-nav-item"><a href="/2018/11/26/Google搜索/" rel="next" title="Google搜索">Google搜索 <i class="fa fa-chevron-right"></i></a></div></div></footer></article></div></div><div class="comments" id="gitalk-container"></div></div><div class="toggle sidebar-toggle"><span class="toggle-line toggle-line-first"></span> <span class="toggle-line toggle-line-middle"></span> <span class="toggle-line toggle-line-last"></span></div><aside class="sidebar"><div class="sidebar-inner"><ul class="sidebar-nav motion-element"><li class="sidebar-nav-toc">文章目录</li><li class="sidebar-nav-overview">站点概览</li></ul><div class="post-toc-wrap sidebar-panel"><div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#经典爬虫框架："><span class="nav-number">1.</span> <span class="nav-text">经典爬虫框架：</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#scrapy框架-任务分离固定明确"><span class="nav-number">2.</span> <span class="nav-text">scrapy框架: 任务分离固定明确</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#spider主程序："><span class="nav-number">2.1.</span> <span class="nav-text">spider主程序：</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#settings："><span class="nav-number">2.2.</span> <span class="nav-text">settings：</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#requests对象：scrapy-Request-类实例化"><span class="nav-number">2.3.</span> <span class="nav-text">requests对象：scrapy.Request()类实例化</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#response对象："><span class="nav-number">2.4.</span> <span class="nav-text">response对象：</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Item："><span class="nav-number">2.5.</span> <span class="nav-text">Item：</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#item-pipeline管道处理组件"><span class="nav-number">2.6.</span> <span class="nav-text">item pipeline管道处理组件:</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#中间件"><span class="nav-number">2.7.</span> <span class="nav-text">中间件</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#process-exception-request-exception-spider"><span class="nav-number">3.</span> <span class="nav-text">process_exception(request, exception, spider)</span></a></li></ol><li class="nav-item nav-level-1"><a class="nav-link" href="#引入开源库"><span class="nav-number"></span> <span class="nav-text">引入开源库</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#异步加多线程"><span class="nav-number">0.1.</span> <span class="nav-text">异步加多线程</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#分布式爬虫-多台主机协同爬取"><span class="nav-number">0.2.</span> <span class="nav-text">分布式爬虫-多台主机协同爬取</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#RedisSpider"><span class="nav-number">0.3.</span> <span class="nav-text">RedisSpider()</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#redis-cli"><span class="nav-number"></span> <span class="nav-text">redis-cli:</span></a></li></div></div><div class="site-overview-wrap sidebar-panel"><div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person"><p class="site-author-name" itemprop="name">zhiheng</p><div class="site-description" itemprop="description">programming and life</div></div><div class="site-state-wrap motion-element"><nav class="site-state"><div class="site-state-item site-state-posts"><a href="/archives/"><span class="site-state-item-count">11</span> <span class="site-state-item-name">日志</span></a></div><div class="site-state-item site-state-categories"><a href="/categories/"><span class="site-state-item-count">10</span> <span class="site-state-item-name">分类</span></a></div><div class="site-state-item site-state-tags"><a href="/tags/"><span class="site-state-item-count">10</span> <span class="site-state-item-name">标签</span></a></div></nav></div><div class="feed-link motion-element"><a href="/atom.xml" rel="alternate"><i class="fa fa-rss"></i>RSS</a></div><div class="links-of-author motion-element"><span class="links-of-author-item"><a href="https://github.com/yuwengeng" title="GitHub → https://github.com/yuwengeng" rel="noopener" target="_blank"><i class="fa fa-fw fa-github"></i>GitHub</a> </span><span class="links-of-author-item"><a href="https://www.cnblogs.com/yuwengeng/" title="博客园 → https://www.cnblogs.com/yuwengeng/" rel="noopener" target="_blank"><i class="fa fa-fw fa-globe"></i>博客园</a> </span><span class="links-of-author-item"><a href="mailto:yuwenzhiheng95@gmail.com" title="E-Mail → mailto:yuwenzhiheng95@gmail.com" rel="noopener" target="_blank"><i class="fa fa-fw fa-envelope"></i>E-Mail</a> </span><span class="links-of-author-item"><a href="https://weibo.com/yourname" title="Weibo → https://weibo.com/yourname" rel="noopener" target="_blank"><i class="fa fa-fw fa-weibo"></i>Weibo</a> </span><span class="links-of-author-item"><a href="https://twitter.com/yourname" title="Twitter → https://twitter.com/yourname" rel="noopener" target="_blank"><i class="fa fa-fw fa-twitter"></i>Twitter</a> </span><span class="links-of-author-item"><a href="https://instagram.com/yourname" title="Instagram → https://instagram.com/yourname" rel="noopener" target="_blank"><i class="fa fa-fw fa-instagram"></i>Instagram</a></span></div></div></div></aside><div id="sidebar-dimmer"></div></div></main><footer class="footer"><div class="footer-inner"><div class="copyright">&copy; <span itemprop="copyrightYear">2019</span> <span class="with-love"><i class="fa fa-heart"></i> </span><span class="author" itemprop="copyrightHolder">zhiheng</span></div><div class="busuanzi-count"><script pjax async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><span class="post-meta-item" id="busuanzi_container_site_uv" style="display:none"><span class="post-meta-item-icon"><i class="fa fa-user"></i> </span><span class="site-uv" title="总访客量"><span id="busuanzi_value_site_uv"></span> </span></span><span class="post-meta-divider">|</span> <span class="post-meta-item" id="busuanzi_container_site_pv" style="display:none"><span class="post-meta-item-icon"><i class="fa fa-eye"></i> </span><span class="site-pv" title="总访问量"><span id="busuanzi_value_site_pv"></span></span></span></div></div></footer></div><script src="//cdn.jsdelivr.net/npm/animejs@3.1.0/lib/anime.min.js"></script><script src="//cdn.jsdelivr.net/gh/theme-next/theme-next-pjax@0/pjax.min.js"></script><script src="/js/utils.js"></script><script src="/js/schemes/muse.js"></script><script src="/js/next-boot.js"></script><script>var pjax = new Pjax({
  selectors: [
    'head title',
    '#page-configurations',
    '.content-wrap',
    '.post-toc-wrap',
    '#pjax'
  ],
  switches: {
    '.post-toc-wrap': Pjax.switches.innerHTML
  },
  analytics: false,
  cacheBust: false,
  scrollTo : !CONFIG.bookmark.enable
});

window.addEventListener('pjax:success', () => {
  document.querySelectorAll('script[pjax], script#page-configurations, #pjax script').forEach(element => {
    var code = element.text || element.textContent || element.innerHTML || '';
    var parent = element.parentNode;
    parent.removeChild(element);
    var script = document.createElement('script');
    if (element.id) {
      script.id = element.id;
    }
    if (element.className) {
      script.className = element.className;
    }
    if (element.type) {
      script.type = element.type;
    }
    if (element.src) {
      script.src = element.src;
      // Force synchronous loading of peripheral JS.
      script.async = false;
    }
    if (element.getAttribute('pjax') !== null) {
      element.setAttribute('pjax', '');
    }
    if (code !== '') {
      script.appendChild(document.createTextNode(code));
    }
    parent.appendChild(script);
  });
  NexT.boot.refresh();
  // Define Motion Sequence & Bootstrap Motion.
  if (CONFIG.motion.enable) {
    NexT.motion.integrator
      .init()
      .add(NexT.motion.middleWares.postList)
      .bootstrap();
  }
  NexT.utils.updateSidebarPosition();
});</script><div id="pjax"><link rel="stylesheet" href="//cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.css"><script>NexT.utils.getScript('//cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.js', () => {
    var gitalk = new Gitalk({
      clientID: '24ef63b5f7c6e9d3a198',
      clientSecret: '5cceec5609a0910c5f361eaaefdbe57ae7c5d359',
      repo: 'yuwengeng.github.io',
      owner: 'yuwengeng',
      admin: ['yuwengeng'],
      id: '26c56a0c64994f936af37dd2579b54b5',
        language: '',
      distractionFreeMode: 'true'
    });
    gitalk.render('gitalk-container');
  }, window.Gitalk);</script></div></body></html>