<!DOCTYPE html>
<html>
<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="utf-8">
  

  
  <title>志恒的博客</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="网络优化HTTP协议：（规范浏览器/服务器req，res信息）- 特点  1. 无连接  2. 无关媒体类型  3. 无状态 - 内容：  请求头，用来说明服务器要使用的附加信息，比较重要的信息有 Cookie Referer User-Agent等 json获取方式:     ajax 请求接口     切换手机移动h5端     app抓包获取     等等 json数据与python语言交互">
<meta property="og:type" content="article">
<meta property="og:title" content="志恒的博客">
<meta property="og:url" content="https://yuwengeng.github.io/2019/06/10/spider/index.html">
<meta property="og:site_name" content="志恒的博客">
<meta property="og:description" content="网络优化HTTP协议：（规范浏览器/服务器req，res信息）- 特点  1. 无连接  2. 无关媒体类型  3. 无状态 - 内容：  请求头，用来说明服务器要使用的附加信息，比较重要的信息有 Cookie Referer User-Agent等 json获取方式:     ajax 请求接口     切换手机移动h5端     app抓包获取     等等 json数据与python语言交互">
<meta property="og:locale" content="default">
<meta property="og:updated_time" content="2019-06-18T10:45:29.768Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="志恒的博客">
<meta name="twitter:description" content="网络优化HTTP协议：（规范浏览器/服务器req，res信息）- 特点  1. 无连接  2. 无关媒体类型  3. 无状态 - 内容：  请求头，用来说明服务器要使用的附加信息，比较重要的信息有 Cookie Referer User-Agent等 json获取方式:     ajax 请求接口     切换手机移动h5端     app抓包获取     等等 json数据与python语言交互">
  
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <link rel="stylesheet" href="/css/style.css">
</head>
</html>
<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">志恒的博客</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
      </nav>
      <nav id="sub-nav">
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="https://yuwengeng.github.io"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main"><article id="post-spider" class="article article-type-post" itemscope="" itemprop="blogPost">
  <div class="article-meta">
    <a href="/2019/06/10/spider/" class="article-date">
  <time datetime="2019-06-10T13:17:43.864Z" itemprop="datePublished">2019-06-10</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="网络优化"><a href="#网络优化" class="headerlink" title="网络优化"></a>网络优化</h1><h3 id="HTTP协议：（规范浏览器-服务器req，res信息）"><a href="#HTTP协议：（规范浏览器-服务器req，res信息）" class="headerlink" title="HTTP协议：（规范浏览器/服务器req，res信息）"></a>HTTP协议：（规范浏览器/服务器req，res信息）</h3><pre><code>- 特点
 1. 无连接
 2. 无关媒体类型
 3. 无状态
- 内容：
 请求头，用来说明服务器要使用的附加信息，比较重要的信息有 Cookie Referer User-Agent等
</code></pre><h3 id="json"><a href="#json" class="headerlink" title="json"></a>json</h3><p>获取方式:<br>     ajax 请求接口<br>     切换手机移动h5端<br>     app抓包获取<br>     等等</p>
<p>json数据与python语言交互：</p>
<p>json.loads json字符串 转 Python数据类型  # 传的字符串的编码不是 UTF-8 的话，需要指定字符编码的参数<br>json.load json文件 转 Python数据类型list dict<br>     ：json.dumps() 序列化时默认使的 ascii 编码 # 添加参数禁用ascii 编码，按 utf-8  实现让中文写入的时候保持为中文<br>     indent=空格数 通过空格的数量进行缩紧</p>
<h3 id="python封装http库：-请求的是源代码"><a href="#python封装http库：-请求的是源代码" class="headerlink" title="python封装http库：# 请求的是源代码"></a>python封装http库：# 请求的是源代码</h3><pre><code>标准urllib库
第三方库request
</code></pre><ol>
<li>urllib库：<ol>
<li>request模块：<br>  urlopen()函数<pre><code>data参数：请求方式变为post
超时处理：设置timeout
</code></pre>   read() 返回二进制代码<br>  Request类<br>  Handler类</li>
</ol>
</li>
</ol>
<pre><code>2. error模块：
     URLError类（作用于request模块的异常）
     HTTPError类(子类)
          三个属性code reason headers

          解析异常：AttributeError：
          标签为None
3. parse模块：（处理url）
     解析urlparse() (根据url的6个部分解析)
     构造urlunparse() params接受长度为6的可迭代对象
         urlsplit()
     合并urljoin()

     url编码转换：
          字符串：urllib.parse.quote(str)  url编码
          unquote() url解码
          字典：  urllib.parse.urlencode(dict) 转化为url参数
</code></pre><ol start="2">
<li><p>requests库</p>
<ol>
<li>处理登录：会话维持 声明一个session对象，自动处理cookies<pre><code>操作session获取数据
</code></pre></li>
</ol>
</li>
</ol>
<pre><code> 2. 证书验证（https协议）
      设置verify=false
      指定cert=（path）

 3. 代理设置

 4. requests异常处理：
      from requests.exceptions import RequestException

获取服务器的原始套接字响应:r.raw  (,stream=True)
r.json() 获取json数据
获取cookies字典：response.cookies.get_dict()

 response属性（6）:
</code></pre><ul>
<li><p>r.status_code</p>
<p>   http请求的返回状态，200表示连接成功，404表示连接失败</p>
</li>
<li><p>r.text</p>
<p>   http响应解码后的str形式，url对应的页面内容</p>
</li>
<li><p>r.encoding  从HTTP header中猜测的响应内容编码方式</p>
</li>
<li><p>r.apparent_encoding</p>
<p>   从内容分析出的响应内容的编码方式（备选编码方式）</p>
</li>
<li><p>r.content</p>
<p>   HTTP响应内容的二进制形式bytes类型</p>
</li>
<li><p>r.headers</p>
<p>   http响应内容的头部内容</p>
</li>
</ul>
<h3 id="bs4（网页解析库，支持多种解析器’html-parser’-‘lxml’）"><a href="#bs4（网页解析库，支持多种解析器’html-parser’-‘lxml’）" class="headerlink" title="bs4（网页解析库，支持多种解析器’html.parser’ ‘lxml’）"></a>bs4（网页解析库，支持多种解析器’html.parser’ ‘lxml’）</h3><pre><code> 先初始化一个bs对象，
 方法：findAll(tag, attributes, recursive, text, limit, keywords) 返回list类型，获取匹配的源代码
    get_text()去除标签 attributes字典封装多个属性值，通过标签的名称和属性来查找标签
    获取属性们：
      ···
      nameList = bs.find_all(text=&apos;the prince&apos;)
      [&apos;the prince&apos;, &apos;the prince&apos;, &apos;the prince&apos;, &apos;the prince&apos;, &apos;the prince&apos;, &apos;the prince&apos;, &apos;the prince&apos;]
      ···

 bs默认取后代所有标签，children（）子标签
 prettify() 以标准缩进输出

 select方法;
    soup.select(css选择器)



lxml解析html代码和文件
    parse_text: etree.HTML(text)  #直接读取字符串
    parse_file：etree.parse()     #文件读取
    # 按字符串序列化 HTML文档
    result = etree.tostring(html)

Xpath选择器
 / 选中子节点  //选中文档所有子孙标签  @属性：获取元素对应属性  tag（）获取标签名
 选中 div 孙 节点 中的 所有 img  response. xpath(&apos;// div/*/ img&apos;)
四个基本方法：
 extract（） 序列化该节点为 Unicode 字符串并返回 list
 css(): 返回该表达式所对应的所有节点的 selector list，语法同 BeautifulSoup4
 re(): 返回 Unicode 字符串 list
列 表
</code></pre><h3 id="pyquery选择器-from-pyquery-import-PyQuery-as-pq"><a href="#pyquery选择器-from-pyquery-import-PyQuery-as-pq" class="headerlink" title="pyquery选择器  from pyquery import PyQuery as pq"></a>pyquery选择器  from pyquery import PyQuery as pq</h3><pre><code>方法：
find()查找子孙节点  children（）查找所有子节点
多个节点.items()方法 返回一个generator

html() attr() 返回第一个节点
text() 返回所有text 中间空格分开，str类型
</code></pre><h2 id="js动态渲染问题："><a href="#js动态渲染问题：" class="headerlink" title="js动态渲染问题："></a>js动态渲染问题：</h2><h3 id="模拟Ajax异步数据爬取-（返回json类型）"><a href="#模拟Ajax异步数据爬取-（返回json类型）" class="headerlink" title="模拟Ajax异步数据爬取 （返回json类型）"></a>模拟Ajax异步数据爬取 （返回json类型）</h3><pre><code>Type：xhr
</code></pre><p>cookies池，代理池，UA（from fake_useragent import UserAgent）</p>
<p>协程的优势：</p>
<p>最大的优势就是协程极高的执行效率。因为子程序切换不是线程切换，而是由程序自身控制，因此，没有线程切换的开销，和多线程比，线程数量越多，协程的性能优势就越明显。</p>
<p>第二大优势就是不需要多线程的锁机制，因为只有一个线程，也不存在同时写变量冲突，在协程中控制共享资源不加锁，只需要判断状态就好了，所以执行效率比多线程高很多</p>
<h3 id="实战经验："><a href="#实战经验：" class="headerlink" title="实战经验："></a>实战经验：</h3><pre><code>进入初始网页
分析翻页url规则
阅读分析源码，
明确数据加载方式

# def write_to_file(content) :
     with open (’result.txt ’,’a ’, encoding=’ utf-8&apos;) as f:   # 用中文编码
          f.write(json.dumps(content ，ensure_ascii=False) +’\n&apos;)
</code></pre><p>模拟登录：<br>    登录刷新：post登录<br>    无刷新：Ajax方式</p>
<pre><code> 1. 分析post请求data内容
 2. get请求登录页，获取set-cookies， 源代码中获取token

- GitHub：先获取token

- 微信登录：
    长轮询
</code></pre><p>模板：</p>
<ol>
<li><p>图片网站<br> 先获取图片链接<br> 下载图片</p>
</li>
<li><p>论坛资源</p>
</li>
<li><p>电商网站</p>
</li>
<li><p>新闻网站</p>
</li>
</ol>
<p>函数封装模板（直接调用）：<br>     getTitle（）<br>     getUrl()</p>
<h3 id="selemium-浏览器自动化"><a href="#selemium-浏览器自动化" class="headerlink" title="selemium 浏览器自动化"></a>selemium 浏览器自动化</h3><pre><code>   from selenium import webdriver
   driver = webdriver.Chrome()
   drive.get(&apos;&apos;)   //打开特定网页
   drive.page_source  //打开网页源码
获取源代码page_source
     获取节点属性等信息
查找节点：（通过XPath/CSS选择器）
     单个节点/多个节点find_element() 返回的是WebElement类型
      * 查找单个节点
          <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> selenium <span class="keyword">import</span> webdriver</span><br><span class="line">browser = webdriver.Chrome()</span><br><span class="line">browser.get(<span class="string">'https://www.taobao.com'</span>)</span><br><span class="line">input_ first = browser.find_element_by_id(<span class="string">'q'</span>)</span><br><span class="line">input_second = browser.find_element_by css_selector   (<span class="string">'#q’)</span></span><br><span class="line"><span class="string">input_third = browser_find_element_by_xpath('</span>//*[@id ＝ 飞”］’）</span><br><span class="line">print(input_first, iput_second, input_third)</span><br><span class="line">browser.close()</span><br></pre></td></tr></table></figure>

          另一种参数的灵活方式：
          `find_element(By.ID, id ）`

          * 多个节点
          `find_elements(By.CSS_SELECTOR,&apos;.service-bd li&apos;) `

节点交互：
     动作链ActionChains

     输入文字时用 `send_keys()`方法，清空文字时用` clear()`方法，点击按钮时用 `click()`方法


(万能方法)模拟运行js：execute_script ()

切换框架：switch_to.frame()

加载等待：
     隐式等待browser.implicitly_ wait(10)
显式等待：



Web 浏览器与 Web 服务器之间将完成下列 7 个步骤：
</code></pre><ol>
<li>建⽴TCP 连接 在 HTTP⼯作开始之前，Web 浏览器⾸先要通过⽹络与<br>Web 服务器建⽴连接，该连接是通过 TCP 来完成的，该协议与 IP 协议<br>共 同构建 Internet，即著名的 TCP/IP 协议族，因此 Internet⼜被称作<br>是 TCP/IP⽹络。HTTP 是⽐TCP（）更⾼层次的应⽤层协议，根据规<br>则， 只有低层协议建⽴之后才能，才能进⾏更层协议的连接，因此，<br>⾸先要 建⽴TCP 连接，⼀般 TCP 连接的端⼝号是 80</li>
<li>Web 浏览器向 Web 服务器发送请求命令 ⼀旦建⽴了 TCP 连接，Web 浏<br>览 器就会向 Web 服务器发送请求命令 例如：GET/sample/hello.jsp<br>HTTP/1.1</li>
<li>Web 浏览器发送请求头信息 浏览器发送其请求命令之后，还要以头信息<br>的形式向 Web 服务器发送⼀些别的信息，之后浏览器发送了⼀空⽩⾏来<br>通知服务器，它已经结束了该头信息的发送。</li>
<li>Web 服务器应答 客户机向服务器发出请求后，服务器会客户机回送应<br>答， HTTP/1.1 200 OK 应答的第⼀部分是协议的版本号和应答状态码</li>
<li>Web 服务器发送应答头信息 正如客户端会随同请求发送关于⾃身的信息<br>⼀样，服务器也会随同应答向⽤户发送关于它⾃⼰的数据及被请求的⽂<br>档。</li>
<li>Web 服务器向浏览器发送数据 Web 服务器向浏览器发送头信息后，它<br>会 发送⼀个空⽩⾏来表示头信息的发送到此为结束，接着，它就以<br>Content-Type 应答头信息所描述的格式发送⽤户所请求的实际数据</li>
<li>Web 服务器关闭 TCP 连接 ⼀般情况下，⼀旦 Web 服务器向浏览器发送<br>了 请求数据，它就要关闭 TCP 连接，然后如果浏览器或者服务器在其<br>头信 息加⼊了这⾏代码 Connection:keep-alive TCP 连接在发送后将仍<br>然保持 打开状态，于是，浏览器可以继续通过相同的连接发送请求。保<br>持连接 节省了为每个请求建⽴新连接所需的时间，还节约了⽹络带宽。</li>
</ol>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://yuwengeng.github.io/2019/06/10/spider/" data-id="cjx1vtdbv0001owm0r61ho1vj" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2019/06/18/简历/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          (no title)
        
      </div>
    </a>
  
  
    <a href="/2019/04/23/XPath/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">XPath</div>
    </a>
  
</nav>

  
</article>

</section>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2019 John Doe<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>



<script src="/js/script.js"></script>



  </div>
</body>
</html>